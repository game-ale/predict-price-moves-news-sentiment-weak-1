ğŸ“ˆ ***Predicting Price Moves with News Sentiment***

***Nova Financial Insights Challenge â€“ Week 1â€“3 Full Project***

***ğŸ” Project Overview***

This repository contains all three tasks of the Nova Financial Insights Challenge:

Task 1 â€“ Exploratory Data Analysis (EDA)

Analyze 1.4M financial news headlines (2011â€“2020) to understand publisher behavior, news timing, headline text patterns, and dataset quality.

Task 2 â€“ Quantitative Stock Analysis

Load historical stock prices, compute technical indicators with TA-Lib, financial metrics with PyNance, and visualize price behavior.

Task 3 â€“ Newsâ€“Price Correlation

Combine news sentiment with stock daily returns to measure correlation between news tone and market movement.


ğŸ§ª Task 1 â€” Financial News Exploratory Data Analysis (EDA)
ğŸ“Œ Dataset Summary

FNSPID Dataset â€” 1,407,328 financial news headlines (2011â€“2020)
After cleaning: ~883k unique articles

ğŸ“Š Key Findings
| Analysis                   | Insight                                                        |
| -------------------------- | -------------------------------------------------------------- |
| **Dataset Size**           | 1.4M rows â†’ 883k unique after URL deduplication                |
| **Duplicate Content**      | 523,899 repeated URLs â†’ heavy news syndication                 |
| **Top Publishers**         | Paul Quintaro, Lisa Levin, Benzinga Newsdesk â†’ 40% of all data |
| **Peak Publication Hours** | **9 AM â€“ 12 PM ET** (pre-market â†’ market open)                 |
| **Headline Length**        | Median 64 chars, Mean 73, 95% < 140 â†’ concise                  |
| **Dominant Topics (LDA)**  | Earnings, M&A, Analyst Ratings, FDA/Regulatory                 |
| **Publisher Domains**      | benzinga.com dominates; many individual analyst emails         |
| **Major Spike**            | March 24, 2020 (COVID crash + Fed intervention)                |


ğŸ–¼ï¸ Visualizations (located in notebooks/reports/)

articles_per_day.png â€“ full timeline, event spikes

articles_per_publisher.png â€“ publisher concentration

wordcloud_headlines.png â€“ common financial keywords

headline_length_dist.png â€“ length distribution

articles_per_hour.png â€“ market-hour bias

domains_per_publisher.png â€“ institutional vs individual sources

ğŸ”§ Technical Highlights â€“ Task 1

Custom NewsAnalyzer class using:

RAKE

spaCy pipelines

TF-IDF

LDA topic modeling

Regex-based financial event detector (M&A, IPO, FDA approval, dividend, etc.)

timezone normalization: UTC â†’ America/New_York

Efficient 20k-row sampling for heavy NLP tasks

Auto-saving plots with semantic filenames

CI/CD: GitHub Actions enabled

ğŸŸ¢ KPIs (Task 1)

âœ” Proper Git branch workflow (task-1)

âœ” Minimum 3 commits/day

âœ” Complete EDA

âœ” Repo structure correct

âœ” CI workflow passing

ğŸ“‰ Task 2 â€” Stock Technical Analysis (TA-Lib & PyNance)
ğŸ“¥ Data Preparation

Load stock prices (Open, High, Low, Close, Volume)

Handle missing dates, holiday gaps

Compute daily OHLC aggregates if needed

ğŸ“ˆ Technical Indicators

Examples implemented:

df['SMA_20'] = talib.SMA(df['Close'], timeperiod=20)
df['RSI'] = talib.RSI(df['Close'], timeperiod=14)
df['MACD'], df['MACD_signal'], df['MACD_hist'] = talib.MACD(df['Close'])


Additional metrics via PyNance:

Volatility

Sharpe ratio

Moving average crossovers

Trend strength scores

ğŸ“Š Visualization Highlights

Price + SMA overlays

RSI oscillation behavior

MACD divergence

Volume spikes

(Figures saved inside notebooks/reports/)

ğŸŸ£ Task 2 KPIs

âœ” Branch created (task-2)

âœ” Indicators computed correctly

âœ” Visualizations included

âœ” Merged Task-1 into main via PR

âœ” Accurate technical analysis

ğŸ“° Task 3 â€” Sentiment vs Stock Movement Correlation
ğŸ§  Sentiment Analysis Example
from textblob import TextBlob
df['sentiment'] = df['headline'].apply(lambda x: TextBlob(x).sentiment.polarity)


Positive sentiment: > 0

Neutral: = 0

Negative: < 0

ğŸ“… Date Alignment

Normalize timestamps (YYYY-MM-DD)

Map news dates â†’ stock trading dates

Multiple headlines/day â†’ aggregate mean sentiment

ğŸ“Š Stock Returns
df['Returns'] = df['Close'].pct_change()

ğŸ”— Correlation Analysis
df[['daily_sentiment', 'Returns']].corr(method="pearson")


Outputs:

Correlation coefficient

Direction of relationship

Strength of predictive value

ğŸŸ¡ Task 3 KPIs

âœ” Sentiment pipeline working

âœ” Daily alignment correct

âœ” Pearson correlation computed

âœ” Branch task-3 created

âœ” Pull Request workflow followed

âš™ï¸ CI/CD â€“ GitHub Actions

The pipeline at:

.github/workflows/unittests.yml


Runs:

Dependency installation

Lint checks

Unit tests (pytest)

Notebook execution tests

ğŸ“¦ Requirements
pandas
numpy
matplotlib
seaborn
nltk
textblob
spacy
scikit-learn
wordcloud
pyyaml
talib
pynance
jupyter
yfinance


ğŸ§  Self-Learning References

scikit-learn: LDA topic modeling

RAKE keyword extraction (original paper)

TextBlob & VADER sentiment analysis

Investopedia market structure

TA-Lib indicator math

ğŸ“Œ Next Steps

Integrate sentiment pipeline with multi-stock universe

Build a daily sentiment index

Perform Granger Causality tests

Build a prediction baseline model

ğŸ‘¤ Author

Gemechu Alemu
November 2025
â€œTurning headlines into actionable alpha.â€

GitHub: https://github.com/game-ale/predict-price-moves-news-sentiment-weak-1